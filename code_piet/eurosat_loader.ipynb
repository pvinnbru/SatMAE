{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2de252ac-7dda-40ac-aa1d-dd97e2656f9e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **1. Generate `train.txt` and `val.txt`**\n",
    "\n",
    "The text files are used for loading Eurosat Data stored in `..\\data\\`. They look like this:\n",
    "\n",
    "```\n",
    "<path_to_image> <label>\n",
    "```\n",
    "For example:\n",
    "```\n",
    "/path/to/image1.tif    0\n",
    "/path/to/image2.tif    3\n",
    "...\n",
    "```\n",
    "\n",
    "The .txt-files are generate from the script below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f22792c6-6e08-4ed4-8de0-88d70ea5dc41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created train/val splits for: ../data/eurosat_ms\n",
      "   → Train: 21600 samples\n",
      "   → Val:   5400 samples\n",
      "✅ Created train/val splits for: ../data/eurosat_rgb\n",
      "   → Train: 21600 samples\n",
      "   → Val:   5400 samples\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import random\n",
    "\n",
    "def generate_split_txt(root_folder, out_txt_path, split_ratio=0.8, seed=42):\n",
    "    \"\"\"\n",
    "    Creates train/val .txt files from a root image folder organized by class.\n",
    "    Supports .tif and .jpg files.\n",
    "    \"\"\"\n",
    "    class_names = sorted(os.listdir(root_folder))\n",
    "    class_to_idx = {cls: idx for idx, cls in enumerate(class_names)}\n",
    "\n",
    "    all_samples = []\n",
    "    for cls in class_names:\n",
    "        tif_paths = glob(os.path.join(root_folder, cls, \"*.tif\"))\n",
    "        jpg_paths = glob(os.path.join(root_folder, cls, \"*.jpg\"))\n",
    "        image_paths = tif_paths + jpg_paths\n",
    "        for path in image_paths:\n",
    "            all_samples.append(f\"{path} {class_to_idx[cls]}\")\n",
    "\n",
    "    if not all_samples:\n",
    "        print(f\"⚠️  No image files found in: {root_folder}\")\n",
    "        return\n",
    "\n",
    "    random.seed(seed)\n",
    "    random.shuffle(all_samples)\n",
    "    split_idx = int(len(all_samples) * split_ratio)\n",
    "    train_samples = all_samples[:split_idx]\n",
    "    val_samples = all_samples[split_idx:]\n",
    "\n",
    "    with open(out_txt_path.replace(\".txt\", \"_train.txt\"), \"w\") as f:\n",
    "        f.write(\"\\n\".join(train_samples))\n",
    "    with open(out_txt_path.replace(\".txt\", \"_val.txt\"), \"w\") as f:\n",
    "        f.write(\"\\n\".join(val_samples))\n",
    "\n",
    "    print(f\"✅ Created train/val splits for: {root_folder}\")\n",
    "    print(f\"   → Train: {len(train_samples)} samples\")\n",
    "    print(f\"   → Val:   {len(val_samples)} samples\")\n",
    "\n",
    "# Execution\n",
    "generate_split_txt(\"../data/eurosat_ms\", \"../data_splits/eurosat_ms.txt\")\n",
    "generate_split_txt(\"../data/eurosat_rgb\", \"../data_splits/eurosat_rgb.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3912d5c8-66f1-4902-86cf-40d61c05a322",
   "metadata": {},
   "source": [
    "### 2. **Create Training Subsets (10%, 25%, 50%, 100%)**\n",
    "\n",
    "The Goal is to measure how model performance improves as the training data size increases. To ensure fair and meaningful comparisons across runs, the validation set remains fixed.\n",
    "\n",
    "The following textfiles were generated and include the complete dataset:\n",
    "\n",
    "```\n",
    "../data_splits/eurosat_ms_train.txt\n",
    "../data_splits/eurosat_rgb_train.txt\n",
    "```\n",
    "\n",
    "To subsample:\n",
    "\n",
    "* Randomly select a percentage of lines from that file\n",
    "* Save them into new files like:\n",
    "\n",
    "  ```\n",
    "  ../data_splits/eurosat_ms_train_10.txt\n",
    "  ../data_splits/eurosat_ms_train_25.txt\n",
    "  ../data_splits/eurosat_ms_train_50.txt\n",
    "  ```\n",
    "\n",
    "Do this for RGB and MS too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48c6dfa3-a5eb-4c73-8b6f-0b1ab4543236",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 10% subset to ../data_splits/eurosat_ms_train_10.txt (2160 samples)\n",
      "Saved 25% subset to ../data_splits/eurosat_ms_train_25.txt (5400 samples)\n",
      "Saved 50% subset to ../data_splits/eurosat_ms_train_50.txt (10800 samples)\n",
      "Saved 75% subset to ../data_splits/eurosat_ms_train_75.txt (16200 samples)\n",
      "Saved 10% subset to ../data_splits/eurosat_rgb_train_10.txt (2160 samples)\n",
      "Saved 25% subset to ../data_splits/eurosat_rgb_train_25.txt (5400 samples)\n",
      "Saved 50% subset to ../data_splits/eurosat_rgb_train_50.txt (10800 samples)\n",
      "Saved 75% subset to ../data_splits/eurosat_rgb_train_75.txt (16200 samples)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def subsample_txt_file(input_path, output_prefix, percentages=[10, 25, 50], seed=42):\n",
    "    with open(input_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    random.seed(seed)\n",
    "    random.shuffle(lines)\n",
    "    \n",
    "    for p in percentages:\n",
    "        count = int(len(lines) * (p / 100))\n",
    "        subset = lines[:count]\n",
    "        out_path = f\"{output_prefix}_{p}.txt\"\n",
    "        with open(out_path, 'w') as f_out:\n",
    "            f_out.writelines(subset)\n",
    "        print(f\"Saved {p}% subset to {out_path} ({count} samples)\")\n",
    "\n",
    "# Example usage\n",
    "subsample_txt_file(\"../data_splits/eurosat_ms_train.txt\", \"../data_splits/eurosat_ms_train\", percentages=[10, 25, 50, 75])\n",
    "subsample_txt_file(\"../data_splits/eurosat_rgb_train.txt\", \"../data_splits/eurosat_rgb_train\", percentages=[10, 25, 50, 75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13aebfa4-9312-4513-b815-10f87f94071d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Search for .pth files recursively\n",
    "for root, dirs, files in os.walk(\".\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".pth\"):\n",
    "            print(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51026407-01ac-4231-9e00-a4c65352222a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
